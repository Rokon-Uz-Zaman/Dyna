{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Blur_inVideo_Colab.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP758VgwKdABnxY1S2oBb2l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rokon-Uz-Zaman/Dyna/blob/master/Face_Blur_inVideo_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9I0OLHbRonUQ"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))"
      ],
      "metadata": {
        "id": "cyCNTI2WotDO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(\"/content/NewsPresenter.mp4\")\n",
        "\n",
        "frameWidth=int(cap.get(3))\n",
        "frameHeight= int(cap.get(4))\n",
        "size=(frameWidth,frameHeight)\n",
        "#result = cv2.VideoWriter('filename.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size)\n",
        "out=cv2.VideoWriter('outputFile.avi',cv2.VideoWriter_fourcc(*'MJPG'),10,size)\n",
        "\n",
        "#out = cv2.VideoWriter('output.mp4',0x7634706d , 20.0, (640,480))\n",
        "\n",
        "while True:\n",
        "      check,img=cap.read() \n",
        "      gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "      #print(gray.shape)\n",
        "      # get face bounding box coordinates using Haar Cascade\n",
        "      faces = face_cascade.detectMultiScale(gray)\n",
        "      # draw face bounding box on image\n",
        "      for (x,y,w,h) in faces:\n",
        "         img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "         #Blur \n",
        "         img[y:y+h,x:x+w]=cv2.medianBlur(img[y:y+h,x:x+w],35)   \n",
        "        \n",
        "      font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "      img=cv2.putText(img,'A.B.M. Rokon-Uz-Zaman Roman',(5,50),font ,2,(0,0,255),10)\n",
        "      #img=cv2.putText(img,' Q  quit video',(1,500),font ,2,(0,0,255),10)\n",
        "      #img=cv2.putText(img,' G  Gray ',(1,600),font ,2,(0,0,255),10)\n",
        "      #img=cv2.putText(img,' H  HSV',(1,700),font ,2,(0,0,255),10)\n",
        "      \n",
        "        \n",
        "      #cv2.imshow('this is gray version j ', img2)\n",
        "      out.write(img) \n",
        "\n",
        "        #cv2.waitKey(100)  # 1sec= 1k milisec\n",
        "        #if cv2.waitKey(100) & 0XFF== ord('q'):\n",
        "            #break\n",
        "      if cv2.waitKey(100) & 0XFF== ord('q'):\n",
        "          cv2.destroyAllWindows()\n",
        "          break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "L-MgqUWwppsM",
        "outputId": "eab43422-5560-4cec-97ce-eef393c8a392"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-94cbf763659e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0;31m#print(gray.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0;31m# get face bounding box coordinates using Haar Cascade\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m       \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_cascade\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetectMultiScale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m       \u001b[0;31m# draw face bounding box on image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "snDX0E_koxiR"
      }
    }
  ]
}